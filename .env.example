# ============================================================================
# Vision Inspection System - Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# ============================================================================
 
# ========================
# REQUIRED: HuggingFace API (for Inspector + Auditor)
# ========================
# Get your key at: https://huggingface.co/settings/tokens
# Free tier: ~1000 req/day for Inference API
HUGGINGFACE_API_KEY=h**************************************EWObf
 
# ========================
# REQUIRED: Groq API (for Explainer - ultra-fast text)
# ========================
# Get your key at: https://console.groq.com/keys
# Free tier: 14,400 req/day, 30 RPM
# NOTE: Groq deprecated vision models, only text models available
GROQ_API_KEY=g**************************************************kYOaPzp
 
# ========================
# VLM Model Configuration
# ========================
# =============================================================================
# VLM MODEL SETTINGS - DUAL MODEL CONSENSUS ARCHITECTURE
# =============================================================================
# IMPORTANT: Using DIFFERENT models for true independent verification!
# Inspector: Qwen2.5-VL (HuggingFace) - Primary detection
# Auditor: Llama 4 Maverick (Groq) - Independent verification with different architecture
 
# INSPECTOR (HuggingFace - Qwen)
    VLM_INSPECTOR_MODEL=Qwen/Qwen2.5-VL-7B-Instruct
    VLM_INSPECTOR_PROVIDER=huggingface
    VLM_INSPECTOR_TEMPERATURE=0.1
    VLM_INSPECTOR_MAX_TOKENS=2048
 
# AUDITOR (Groq - Llama 4 Maverick) - DIFFERENT MODEL FOR TRUE CONSENSUS
VLM_AUDITOR_MODEL=meta-llama/llama-4-maverick-17b-128e-instruct
VLM_AUDITOR_PROVIDER=groq
VLM_AUDITOR_TEMPERATURE=0.1
VLM_AUDITOR_MAX_TOKENS=2048
 
# Explainer: Llama 3.3 70B (Groq) - Ultra-fast text generation
EXPLAINER_MODEL=llama-3.1-8b-instant
EXPLAINER_TEMPERATURE=0.3
EXPLAINER_MAX_TOKENS=1024
 
# ========================
# Safety Configuration
# ========================
CONFIDENCE_THRESHOLD=0.7
MAX_DEFECTS_AUTO=2
VLM_AGREEMENT_REQUIRED=true
HIGH_CRITICALITY_REQUIRES_REVIEW=true
LOW_CONFIDENCE_THRESHOLD=0.5
 
# ========================
# LangSmith Observability (Recommended)
# ========================
LANGSMITH_API_KEY=lsv*********************************************dd1
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=vision-inspection-system
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
 
# ========================
# Database Configuration
# ========================
DATABASE_PATH=data/inspections.db
DATABASE_ECHO=false
CHAT_HISTORY_DB=data/chat_history.db
 
# ========================
# File Storage
# ========================
UPLOAD_DIR=data/uploads
REPORT_DIR=data/reports
LOG_DIR=data/logs
MAX_FILE_SIZE_MB=10
ALLOWED_EXTENSIONS=jpg,jpeg,png,bmp,tiff,webp
 
# ========================
# Logging
# ========================
LOG_LEVEL=INFO
LOG_FORMAT=detailed
LOG_TO_CONSOLE=true
LOG_TO_FILE=true
LOG_TO_LANGSMITH=true
 
# ========================
# API Configuration
# ========================
API_TIMEOUT=60
API_MAX_RETRIES=3
API_RETRY_BACKOFF=2
 
# ========================
# Chat Memory
# ========================
ENABLE_CHAT_MEMORY=true
MAX_CHAT_HISTORY=50
 
# ========================
# UI Configuration
# ========================
APP_TITLE=Vision Inspection System
DEFAULT_CRITICALITY=medium
SHOW_DEBUG_INFO=false
ENABLE_ANALYTICS=true
 
# ========================
# Performance
# ========================
ENABLE_STREAMING=true
MAX_CONCURRENT_CALLS=3
MAX_IMAGE_DIMENSION=2048
 
# ========================
# Environment
# ========================
ENVIRONMENT=development
SKIP_HEALTH_CHECKS=false
USE_MOCK_RESPONSES=false
VERBOSE_ERRORS=true